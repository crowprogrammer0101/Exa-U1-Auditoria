# Exa-U1-Auditoria

Bit√°cora de Implementaci√≥n y Ejecuci√≥n
Sistema de Gesti√≥n de Riesgos para Activos Digitales
(Proyecto de Auditor√≠a ‚Äì UPT | Abril‚ÄØ2025)
________________________________________
1. Entorno de trabajo
Componente	Versi√≥n	Observaciones
SO	Windows 10 Pro 64‚ÄØbit	Local del auditor
PowerShell	7.4 (pwsh)	Terminal integrada en VS Code
VS Code	1.89	Carpeta abierta: D:\UPT\AUDITOR√çA DE SISTEMAS\Examen U1\A analizar\AuditoriaRiesgos
Git	2.44	Clonaci√≥n del repositorio base
Node.js	18.x	Instalado a nivel sistema
Python	3.12 (venv .venv)	Activado con \.venv\Scripts\activate
Ollama	0.6.6	Instalador oficial ‚Äì agrega ruta al‚ÄØPATH
Ruta ra√≠z del proyecto utilizada en todos los pasos:
D:\UPT\AUDITOR√çA DE SISTEMAS\Examen U1\A analizar\AuditoriaRiesgos
________________________________________
2. Clonaci√≥n del repositorio base
git clone https://github.com/OscarJimenezFlores/CursoAuditoria.git
cd CursoAuditoria\AuditoriaRiesgos   # se renombr√≥ l√≥gicamente a AuditoriaRiesgos
________________________________________
3. Instalaciones y configuraciones realizadas
3.1 Front end
# Dentro de la ra√≠z del proyecto
npm install           # descarga dependencias
npm run build         # genera carpeta dist/ (Vite + React 18 + Ant Design)
3.2 Backend (Flask)
python -m venv .venv
\.venv\Scripts\activate
pip install flask openai requests
Ajustes de c√≥digo
‚Ä¢	app.py ‚ûú Se a√±adi√≥ autenticaci√≥n ficticia y rutas /analizar-riesgos y /sugerir-tratamiento.
‚Ä¢	Se cambi√≥ la l√≠nea model ‚Üí model="llama3" en funciones obtener_riesgos() y obtener_tratamiento().
3.3 Ollama & modelo LLaMA 3
# Descarga del modelo
ollama pull llama3

# Ejecuci√≥n permanente (puerto 11434 por defecto)
ollama run llama3     # terminal 1
Comprobaci√≥n:
curl http://localhost:11434/v1/models  # -> 200 OK
________________________________________
4. Ejecuci√≥n paso a paso
Terminal	Comando	Ubicaci√≥n
T 1	ollama run llama3	Ra√≠z del proyecto (modelo)
T 2	\.venv\Scripts\activate``python app.py	Ra√≠z (backend escuchando en :5500)
T 3	python auto_eval.py	Ra√≠z (script autom√°tico)
________________________________________
5. Script auto_eval.py
‚Ä¢	Crea la lista de 5 activos (servidor BD, aplicaci√≥n banca, firewall, VPN, BDD clientes).
‚Ä¢	Env√≠a POST ‚Üí /analizar-riesgos y posteriormente a /sugerir-tratamiento.
‚Ä¢	Guarda log en resultados_riesgos.txt.
Ubicaci√≥n del archivo:
D:\...\AuditoriaRiesgos\resultados_riesgos.txt
________________________________________
6. Problemas y soluciones encontradas
Incidencia	S√≠ntoma	Soluci√≥n
ollama no reconocido	CommandNotFound	A√±adir C:\Users\<user>\AppData\Local\Programs\Ollama al PATH
ModuleNotFoundError: requests / flask / openai	Backend no inicia	pip install <paquete> dentro del venv
openai.NotFoundError model "ramiro:instruct"	404 en endpoints	Cambiar a model="llama3" o ollama pull modelo_personal
Conexi√≥n rechazada a localhost:5500	WinError 10061 en script	Iniciar app.py antes de auto_eval.py
________________________________________
7. Resultado final
‚Ä¢	Backend accesible en http://localhost:5500/login ‚Üí autenticaci√≥n admin / 1234.
‚Ä¢	Frontend servido desde dist/index.html despu√©s del login.
‚Ä¢	Script autom√°tico genera reporte con riesgos, impactos y tratamientos, almacenado en resultados_riesgos.txt.
________________________________________
8. Archivos clave del proyecto
AuditoriaRiesgos/
‚îú‚îÄ app.py                  # servidor Flask + endpoints
‚îú‚îÄ auto_eval.py            # script de evaluaci√≥n autom√°tica
‚îú‚îÄ package.json            # dependencias frontend
‚îú‚îÄ vite.config.js          # configuraci√≥n Vite
‚îú‚îÄ src/                    # c√≥digo React
‚îú‚îÄ dist/                   # build generado por Vite
‚îî‚îÄ resultados_riesgos.txt  # salida del an√°lisis
________________________________________
9. Pr√≥ximos pasos sugeridos
1.	Dise√±ar plantilla PDF para exportar resultados_riesgos.txt.
2.	Dockerizar backend + Ollama para despliegue sencillo.
3.	Implementar control de sesiones y logout seguro.


‚ÄÉ
Anexos de C√≥digo
Anexo A ‚Äì auto_eval.py
Script en Python que automatiza el ciclo completo "analizar‚ÄÜ‚ûú‚ÄÜsugerir tratamiento" para los cinco activos solicitados y genera resultados_riesgos.txt.
"""auto_eval.py ‚Äì Ejecuci√≥n autom√°tica de an√°lisis y tratamientos ISO 27001
Autor: <tu‚ÄØnombre>
Fecha: abril‚ÄØ2025

Requisitos previos:
‚Ä¢ Ollama ejecutando el modelo llama3 en http://localhost:11434
   $ ollama run llama3
‚Ä¢ Backend Flask ejecut√°ndose en http://localhost:5500
   $ python app.py
‚Ä¢ Paquete Python requests instalado
   $ pip install requests
"""
import requests

URL_BACKEND = "http://localhost:5500"
ARCHIVO_SALIDA = "resultados_riesgos.txt"

activos = [
    {"activo": "Servidor de Base de Datos", "tipo": "Base de Datos"},
    {"activo": "Aplicaci√≥n Web de Banca", "tipo": "Aplicaci√≥n"},
    {"activo": "Firewall Perimetral", "tipo": "Seguridad"},
    {"activo": "VPN Corporativa", "tipo": "Infraestructura"},
    {"activo": "Base de Datos Clientes", "tipo": "Informaci√≥n"}
]

def analizar_y_tratar(activo: dict, fp):
    """Lanza los dos endpoints del backend y escribe resultados en disco."""
    fp.write(f"\nüîç Activo: {activo['activo']} ({activo['tipo']})\n")
    print(f"\nüîç Analizando: {activo['activo']}")

    # 1) Analizar riesgos
    r = requests.post(f"{URL_BACKEND}/analizar-riesgos", json={"activo": activo["activo"]})
    if r.status_code != 200:
        msg = f"‚ùå Error an√°lisis: {r.text}"
        fp.write(msg + "\n")
        print(msg)
        return

    riesgos = r.json()["riesgos"]
    impactos = r.json()["impactos"]

    # 2) Para cada riesgo, pedir tratamiento
    for riesgo, impacto in zip(riesgos, impactos):
        fp.write(f"‚ö†Ô∏è Riesgo: {riesgo}\n‚û°Ô∏è Impacto: {impacto}\n")
        print(f"‚ö†Ô∏è Riesgo: {riesgo} ‚Äî Impacto: {impacto}")

        t = requests.post(f"{URL_BACKEND}/sugerir-tratamiento", json={
            "activo": activo["activo"],
            "riesgo": riesgo,
            "impacto": impacto
        })
        if t.status_code == 200:
            tratamiento = t.json()["tratamiento"]
            fp.write(f"üíä Tratamiento: {tratamiento}\n\n")
            print(f"üíä Tratamiento: {tratamiento}\n")
        else:
            err = f"‚ùå Error tratamiento: {t.text}"
            fp.write(err + "\n\n")
            print(err)

if __name__ == "__main__":
    with open(ARCHIVO_SALIDA, "w", encoding="utf-8") as fp:
        fp.write("üìã RESULTADO DEL AN√ÅLISIS AUTOMATIZADO DE RIESGOS\n" + "="*50 + "\n")
        for act in activos:
            analizar_y_tratar(act, fp)
    print(f"\n‚úÖ Archivo generado: {ARCHIVO_SALIDA}")
________________________________________
Anexo B ‚Äì Modificaciones en app.py
Solo se cambiaron las funciones que interact√∫an con Ollama para apuntar al modelo llama3 (sin sufijo) que fue descargado con ollama pull llama3.
1. Cliente OpenAI (sin cambios, referencia a puerto 11434)
client = OpenAI(
    base_url="http://localhost:11434/v1",
    api_key="ollama"  # requerido pero ignorado por Ollama
)
2. Funci√≥n obtener_riesgos
def obtener_riesgos(activo: str):
    response = client.chat.completions.create(
        model="llama3",   # <-- antes: "ramiro:instruct" / "llama3:instruct"
        messages=[
            {"role": "system", "content": "Responde en espa√±ol, eres una herramienta para gesti√≥n de riesgos ISO 27001..."},
            {"role": "user", "content": "mi raspberry pi"},
            {"role": "assistant", "content": "‚Ä¢ **Acceso no autorizado**: ..."},
            {"role": "user", "content": activo}
        ]
    )
    texto = response.choices[0].message.content
    patron = r"\*\*\s*(.+?)\*\*:\s*(.+?)\.(?=\s*\n|\s*$)"
    pares = re.findall(patron, texto)
    riesgos  = [p[0] for p in pares]
    impactos = [p[1] for p in pares]
    return riesgos, impactos
3. Funci√≥n obtener_tratamiento
def obtener_tratamiento(entrada: str):
    response = client.chat.completions.create(
        model="llama3",   # <-- antes: "ramiro:instruct" / "llama3:instruct"
        messages=[
            {"role": "system", "content": "Responde en espa√±ol, eres una herramienta para gesti√≥n de riesgos ISO 27001..."},
            {"role": "user", "content": "mi telefono movil;Acceso no autorizado;un atacante puede acceder..."},
            {"role": "assistant", "content": "Establecer un bloqueo de la pantalla..."},
            {"role": "user", "content": entrada}
        ]
    )
    return response.choices[0].message.content
Nota: No hubo m√°s cambios en rutas, l√≥gica de sesi√≥n ni validaciones. El backend permanece escuchando en http://0.0.0.0:5500.
________________________________________
Fin de Anexos
